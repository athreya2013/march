{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "counting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Z5sJ59mQel"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqz3bIxdmWqV"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "\r\n",
        "class Counter(nn.Module):\r\n",
        "    \"\"\" Counting module as proposed in [1].\r\n",
        "    Count the number of objects from a set of bounding boxes and a set of scores for each bounding box.\r\n",
        "    This produces (self.objects + 1) number of count features.\r\n",
        "\r\n",
        "    [1]: Yan Zhang, Jonathon Hare, Adam PrÃ¼gel-Bennett: Learning to Count Objects in Natural Images for Visual Question Answering.\r\n",
        "    https://openreview.net/forum?id=B12Js_yRb\r\n",
        "    \"\"\"\r\n",
        "    def __init__(self, objects, already_sigmoided=False):\r\n",
        "        super().__init__()\r\n",
        "        self.objects = objects\r\n",
        "        self.already_sigmoided = already_sigmoided\r\n",
        "        self.f = nn.ModuleList([PiecewiseLin(16) for _ in range(16)])\r\n",
        "\r\n",
        "    def forward(self, boxes, attention):\r\n",
        "        \"\"\" Forward propagation of attention weights and bounding boxes to produce count features.\r\n",
        "        `boxes` has to be a tensor of shape (n, 4, m) with the 4 channels containing the x and y coordinates of the top left corner and the x and y coordinates of the bottom right corner in this order.\r\n",
        "        `attention` has to be a tensor of shape (n, m). Each value should be in [0, 1] if already_sigmoided is set to True, but there are no restrictions if already_sigmoided is set to False. This value should be close to 1 if the corresponding boundign box is relevant and close to 0 if it is not.\r\n",
        "        n is the batch size, m is the number of bounding boxes per image.\r\n",
        "        \"\"\"\r\n",
        "        # only care about the highest scoring object proposals\r\n",
        "        # the ones with low score will have a low impact on the count anyway\r\n",
        "        boxes, attention = self.filter_most_important(self.objects, boxes, attention)\r\n",
        "        # normalise the attention weights to be in [0, 1]\r\n",
        "        if not self.already_sigmoided:\r\n",
        "            attention = F.sigmoid(attention)\r\n",
        "\r\n",
        "        relevancy = self.outer_product(attention)\r\n",
        "        distance = 1 - self.iou(boxes, boxes)\r\n",
        "\r\n",
        "        # intra-object dedup\r\n",
        "        score = self.f[0](relevancy) * self.f[1](distance)\r\n",
        "\r\n",
        "        # inter-object dedup\r\n",
        "        dedup_score = self.f[3](relevancy) * self.f[4](distance)\r\n",
        "        dedup_per_entry, dedup_per_row = self.deduplicate(dedup_score, attention)\r\n",
        "        score = score / dedup_per_entry\r\n",
        "\r\n",
        "        # aggregate the score\r\n",
        "        # can skip putting this on the diagonal since we're just summing over it anyway\r\n",
        "        correction = self.f[0](attention * attention) / dedup_per_row\r\n",
        "        score = score.sum(dim=2).sum(dim=1, keepdim=True) + correction.sum(dim=1, keepdim=True)\r\n",
        "        score = (score + 1e-20).sqrt()\r\n",
        "        one_hot = self.to_one_hot(score)\r\n",
        "\r\n",
        "        att_conf = (self.f[5](attention) - 0.5).abs()\r\n",
        "        dist_conf = (self.f[6](distance) - 0.5).abs()\r\n",
        "        conf = self.f[7](att_conf.mean(dim=1, keepdim=True) + dist_conf.mean(dim=2).mean(dim=1, keepdim=True))\r\n",
        "\r\n",
        "        return one_hot * conf\r\n",
        "\r\n",
        "    def deduplicate(self, dedup_score, att):\r\n",
        "        # using outer-diffs\r\n",
        "        att_diff = self.outer_diff(att)\r\n",
        "        score_diff = self.outer_diff(dedup_score)\r\n",
        "        sim = self.f[2](1 - score_diff).prod(dim=1) * self.f[2](1 - att_diff)\r\n",
        "        # similarity for each row\r\n",
        "        row_sims = sim.sum(dim=2)\r\n",
        "        # similarity for each entry\r\n",
        "        all_sims = self.outer_product(row_sims)\r\n",
        "        return all_sims, row_sims\r\n",
        "\r\n",
        "    def to_one_hot(self, scores):\r\n",
        "        \"\"\" Turn a bunch of non-negative scalar values into a one-hot encoding.\r\n",
        "        E.g. with self.objects = 3, 0 -> [1 0 0 0], 2.75 -> [0 0 0.25 0.75].\r\n",
        "        \"\"\"\r\n",
        "        # sanity check, I don't think this ever does anything (it certainly shouldn't)\r\n",
        "        scores = scores.clamp(min=0, max=self.objects)\r\n",
        "        # compute only on the support\r\n",
        "        i = scores.long().data\r\n",
        "        f = scores.frac()\r\n",
        "        # target_l is the one-hot if the score is rounded down\r\n",
        "        # target_r is the one-hot if the score is rounded up\r\n",
        "        target_l = scores.data.new(i.size(0), self.objects + 1).fill_(0)\r\n",
        "        target_r = scores.data.new(i.size(0), self.objects + 1).fill_(0)\r\n",
        "\r\n",
        "        target_l.scatter_(dim=1, index=i.clamp(max=self.objects), value=1)\r\n",
        "        target_r.scatter_(dim=1, index=(i + 1).clamp(max=self.objects), value=1)\r\n",
        "        # interpolate between these with the fractional part of the score\r\n",
        "        return (1 - f) * Variable(target_l) + f * Variable(target_r)\r\n",
        "\r\n",
        "    def filter_most_important(self, n, boxes, attention):\r\n",
        "        \"\"\" Only keep top-n object proposals, scored by attention weight \"\"\"\r\n",
        "        attention, idx = attention.topk(n, dim=1, sorted=False)\r\n",
        "        idx = idx.unsqueeze(dim=1).expand(boxes.size(0), boxes.size(1), idx.size(1))\r\n",
        "        boxes = boxes.gather(2, idx)\r\n",
        "        return boxes, attention\r\n",
        "\r\n",
        "    def outer(self, x):\r\n",
        "        size = tuple(x.size()) + (x.size()[-1],)\r\n",
        "        a = x.unsqueeze(dim=-1).expand(*size)\r\n",
        "        b = x.unsqueeze(dim=-2).expand(*size)\r\n",
        "        return a, b\r\n",
        "\r\n",
        "    def outer_product(self, x):\r\n",
        "        # Y_ij = x_i * x_j\r\n",
        "        a, b = self.outer(x)\r\n",
        "        return a * b\r\n",
        "\r\n",
        "    def outer_diff(self, x):\r\n",
        "        # like outer products, except taking the absolute difference instead\r\n",
        "        # Y_ij = | x_i - x_j |\r\n",
        "        a, b = self.outer(x)\r\n",
        "        return (a - b).abs()\r\n",
        "\r\n",
        "    def iou(self, a, b):\r\n",
        "        # this is just the usual way to IoU from bounding boxes\r\n",
        "        inter = self.intersection(a, b)\r\n",
        "        area_a = self.area(a).unsqueeze(2).expand_as(inter)\r\n",
        "        area_b = self.area(b).unsqueeze(1).expand_as(inter)\r\n",
        "        return inter / (area_a + area_b - inter + 1e-12)\r\n",
        "\r\n",
        "    def area(self, box):\r\n",
        "        x = (box[:, 2, :] - box[:, 0, :]).clamp(min=0)\r\n",
        "        y = (box[:, 3, :] - box[:, 1, :]).clamp(min=0)\r\n",
        "        return x * y\r\n",
        "\r\n",
        "    def intersection(self, a, b):\r\n",
        "        size = (a.size(0), 2, a.size(2), b.size(2))\r\n",
        "        min_point = torch.max(\r\n",
        "            a[:, :2, :].unsqueeze(dim=3).expand(*size),\r\n",
        "            b[:, :2, :].unsqueeze(dim=2).expand(*size),\r\n",
        "        )\r\n",
        "        max_point = torch.min(\r\n",
        "            a[:, 2:, :].unsqueeze(dim=3).expand(*size),\r\n",
        "            b[:, 2:, :].unsqueeze(dim=2).expand(*size),\r\n",
        "        )\r\n",
        "        inter = (max_point - min_point).clamp(min=0)\r\n",
        "        area = inter[:, 0, :, :] * inter[:, 1, :, :]\r\n",
        "        return area\r\n",
        "\r\n",
        " \r\n",
        "class PiecewiseLin(nn.Module):\r\n",
        "    def __init__(self, n):\r\n",
        "        super().__init__()\r\n",
        "        self.n = n\r\n",
        "        self.weight = nn.Parameter(torch.ones(n + 1))\r\n",
        "        # the first weight here is always 0 with a 0 gradient\r\n",
        "        self.weight.data[0] = 0\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # all weights are positive -> function is monotonically increasing\r\n",
        "        w = self.weight.abs()\r\n",
        "        # make weights sum to one -> f(1) = 1\r\n",
        "        w = w / w.sum()\r\n",
        "        w = w.view([self.n + 1] + [1] * x.dim())\r\n",
        "        # keep cumulative sum for O(1) time complexity\r\n",
        "        csum = w.cumsum(dim=0)\r\n",
        "        csum = csum.expand((self.n + 1,) + tuple(x.size()))\r\n",
        "        w = w.expand_as(csum)\r\n",
        "\r\n",
        "        # figure out which part of the function the input lies on\r\n",
        "        y = self.n * x.unsqueeze(0)\r\n",
        "        idx = Variable(y.long().data)\r\n",
        "        f = y.frac()\r\n",
        "\r\n",
        "        # contribution of the linear parts left of the input\r\n",
        "        x = csum.gather(0, idx.clamp(max=self.n))\r\n",
        "        # contribution within the linear segment the input falls into\r\n",
        "        x = x + f * w.gather(0, (idx + 1).clamp(max=self.n))\r\n",
        "        return x.squeeze(0)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}