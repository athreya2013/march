{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmnCfSV8DNuJ08B9M419dG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/athreya2013/march/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoB6NDlPrHvF"
      },
      "source": [
        "import sys\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "from torch.autograd import Variable\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import data\r\n",
        "import model\r\n",
        "\r\n",
        "\r\n",
        "def extract_plins(net):\r\n",
        "    plins = [net.counter.f[i] for i in range(8)]\r\n",
        "    return [p.weight.data.cpu().clone() for p in plins]\r\n",
        "\r\n",
        "\r\n",
        "def get_loader(*args, **kwargs):\r\n",
        "    dataset = data.ToyTask(*args, **kwargs)\r\n",
        "    loader = torch.utils.data.DataLoader(\r\n",
        "        dataset,\r\n",
        "        batch_size=1024,\r\n",
        "        num_workers=8,\r\n",
        "        pin_memory=True,\r\n",
        "    )\r\n",
        "    return loader\r\n",
        "\r\n",
        "\r\n",
        "def run(nets, loader, iterations, train):\r\n",
        "    if train:\r\n",
        "        [net.train() for net in nets]\r\n",
        "    else:\r\n",
        "        [net.eval() for net in nets]\r\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.01) for net in nets]\r\n",
        "\r\n",
        "    loss_function = nn.CrossEntropyLoss()\r\n",
        "    data = []\r\n",
        "    tq = tqdm(loader, total=iterations, ncols=0, position=2, desc='train' if train else 'val')\r\n",
        "    for i, (a, b, c) in enumerate(tq):\r\n",
        "        if i >= iterations:\r\n",
        "            break\r\n",
        "\r\n",
        "        a = Variable(a.cuda(async=True), requires_grad=False)\r\n",
        "        b = Variable(b.cuda(async=True).transpose(1, 2).contiguous(), requires_grad=False)\r\n",
        "        c = Variable(c.cuda(async=True), requires_grad=False)\r\n",
        "\r\n",
        "        pred_cs = [net(a, b) for net in nets]\r\n",
        "        losses = [loss_function(pred_c, c) for pred_c in pred_cs]\r\n",
        "\r\n",
        "        if train:\r\n",
        "            [optimizer.zero_grad() for optimizer in optimizers]\r\n",
        "            [loss.backward() for loss in losses]\r\n",
        "            [optimizer.step() for optimizer in optimizers]\r\n",
        "            data.append(extract_plins(nets[0]))\r\n",
        "        else:\r\n",
        "            acc = [(pred_c.data.max(dim=1)[1] == c.data).float().mean() for pred_c in pred_cs]\r\n",
        "            data.append(acc)\r\n",
        "    data = list(zip(*data))\r\n",
        "    if not train:\r\n",
        "        data = [np.mean(d) for d in data]\r\n",
        "    return data\r\n",
        "\r\n",
        "\r\n",
        "def main(objects, **kwargs):\r\n",
        "    nets = [\r\n",
        "        model.Net(objects).cuda(),\r\n",
        "        model.Baseline(objects).cuda(),\r\n",
        "    ]\r\n",
        "    loader = get_loader(objects, **kwargs)\r\n",
        "    plins = run(nets, loader, 1000, train=True)\r\n",
        "    accs = run(nets, loader, 200, train=False)\r\n",
        "    return {'plins': plins, 'accs': accs}\r\n",
        "\r\n",
        "\r\n",
        "resolution = 100 + 1\r\n",
        "configuration = sys.argv[1]\r\n",
        "\r\n",
        "params = {\r\n",
        "    'easy': {\r\n",
        "        'objects': 10,\r\n",
        "        'coord': 0.0,\r\n",
        "        'noise': 0.0,\r\n",
        "    },\r\n",
        "    'hard': {\r\n",
        "        'objects': 10,\r\n",
        "        'coord': 0.5,\r\n",
        "        'noise': 0.5,\r\n",
        "    },\r\n",
        "}[configuration]\r\n",
        "\r\n",
        "param_ranges = {\r\n",
        "    'coord': torch.linspace(0, 1, resolution),\r\n",
        "    'noise': torch.linspace(0, 1, resolution),\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "for name, ran in tqdm(param_ranges.items(), ncols=0, desc='all', position=0):\r\n",
        "    logs = []\r\n",
        "    for x in tqdm(ran, ncols=0, desc=name, position=1):\r\n",
        "        p = dict(params)\r\n",
        "        p[name] = x\r\n",
        "        log = main(**p)\r\n",
        "        log['config'] = p\r\n",
        "        logs.append(log)\r\n",
        "    filename = '{}-{}.pth'.format(name, configuration)\r\n",
        "    torch.save(logs, filename)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}